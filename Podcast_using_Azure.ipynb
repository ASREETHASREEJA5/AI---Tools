{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNa7BGv+Oj2//s7xCpE0Hs2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ASREETHASREEJA5/AI---Tools/blob/main/Podcast_using_Azure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK6rPvZqkzrW",
        "outputId": "a89ed8cc-29f2-4eb8-f2a1-f10a61ab5957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-cognitiveservices-speech\n",
            "  Downloading azure_cognitiveservices_speech-1.41.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Downloading azure_cognitiveservices_speech-1.41.1-py3-none-manylinux1_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: azure-cognitiveservices-speech\n",
            "Successfully installed azure-cognitiveservices-speech-1.41.1\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.2.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.15.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.3.29)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.10.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_groq) (0.2.10)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_groq) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_groq) (9.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_groq) (3.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_groq) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_groq) (2.3.0)\n",
            "Downloading langchain_groq-0.2.3-py3-none-any.whl (14 kB)\n",
            "Downloading groq-0.15.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain_groq\n",
            "Successfully installed groq-0.15.0 langchain_groq-0.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install azure-cognitiveservices-speech\n",
        "!pip install python-dotenv\n",
        "!pip install pydub\n",
        "!pip install langchain_groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SPEECH_KEY = \"your key\"\n",
        "SPEECH_REGION = \"eastus\""
      ],
      "metadata": {
        "id": "tynY9ZIBk0a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "podcast generation with emotions asynchronous code"
      ],
      "metadata": {
        "id": "ZRmUUilllDYd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pBhln0QplBEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import os\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "from pydub import AudioSegment\n",
        "from langchain_groq import ChatGroq\n",
        "import json\n",
        "\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key='your_key',\n",
        "    model_name=\"llama-3.1-70b-versatile\"\n",
        ")\n",
        "\n",
        "async def text_to_speech_async(ssml, output_wav_file):\n",
        "    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)\n",
        "\n",
        "    os.makedirs(os.path.dirname(output_wav_file), exist_ok=True)\n",
        "\n",
        "    audio_config = speechsdk.audio.AudioOutputConfig(filename=output_wav_file)\n",
        "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
        "\n",
        "    result_future = synthesizer.speak_ssml_async(ssml)\n",
        "\n",
        "    result = await asyncio.to_thread(result_future.get)\n",
        "\n",
        "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
        "        return output_wav_file\n",
        "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
        "        cancellation_details = result.cancellation_details\n",
        "        raise Exception(f\"Speech synthesis canceled: {cancellation_details.reason} - {cancellation_details.error_details}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "async def generate_dialogue_audio(dialogue, voices, output_dir, final_output_file):\n",
        "    audio_files = []\n",
        "\n",
        "    tasks = []\n",
        "\n",
        "    for idx, line in enumerate(dialogue):\n",
        "      for speaker, content in line.items():\n",
        "        text, emotion = content.rsplit(\",\", 1) if \",\" in content else (content, \"neutral\")\n",
        "        emotion = emotion.strip()\n",
        "\n",
        "        voice = \"en-US-JennyNeural\" if speaker == \"female\" else \"en-US-GuyNeural\"\n",
        "\n",
        "        ssml = f\"\"\"\n",
        "            <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"http://www.w3.org/2001/mstts\" xml:lang=\"en-US\">\n",
        "                <voice name=\"{voice}\">\n",
        "                    <mstts:express-as style=\"{emotion}\">\n",
        "                        {text}\n",
        "                    </mstts:express-as>\n",
        "                </voice>\n",
        "            </speak>\n",
        "            \"\"\"\n",
        "\n",
        "        temp_audio_file = os.path.join(output_dir, f\"temp_dialogue_{idx+1}_{speaker}.wav\")\n",
        "        tasks.append(text_to_speech_async(ssml, temp_audio_file))\n",
        "\n",
        "    # Wait for all tasks to complete and get their results\n",
        "    audio_files = await asyncio.gather(*tasks)\n",
        "\n",
        "    final_audio_path = combine_audio_files(audio_files, final_output_file)\n",
        "\n",
        "\n",
        "    for temp_audio_file in audio_files:\n",
        "        os.remove(temp_audio_file)\n",
        "\n",
        "    return final_audio_path\n",
        "\n",
        "\n",
        "def combine_audio_files(audio_files, final_output_file):\n",
        "    \"\"\"Combines the individual audio files into a final output file.\"\"\"\n",
        "    combined_audio = AudioSegment.empty()\n",
        "    for audio_file in audio_files:\n",
        "        audio_segment = AudioSegment.from_wav(audio_file)\n",
        "        combined_audio += audio_segment\n",
        "\n",
        "    # Export the combined audio to the final output file\n",
        "    combined_audio.export(final_output_file, format=\"wav\")\n",
        "    return final_output_file\n",
        "\n",
        "\n",
        "async def main():\n",
        "    que = input()\n",
        "    langCode = \"en\"\n",
        "    prompt = f\"\"\"\n",
        "You are an AI model designed to generate structured conversational content.\n",
        "- Please provide an answer to the following question : \"{que}\",with given langCode\"{langCode}\" in the specified JSON format.\n",
        "- Ensure the response includes a title, language code, and dialogue with multiple participants also with emotion which best suites for dialouge at end of each dialogue seperated by ',' with dialouge.\n",
        "- Only use one of the following emotions: advertisement_upbeat, affectionate, angry, assistant, calm, chat, cheerful, customerservice, depressed, disgruntled, documentary-narration, embarrassed, empathetic, envious, excited, fearful, friendly, gentle, hopeful, lyrical, narration-professional, narration-relaxed, newscast, newscast-casual, newscast-formal, poetry-reading, sad, serious, shouting, sports_commentary, sports_commentary_excited, whispering, terrified, unfriendly.\n",
        "- Make it engaging, informative, and structured.\n",
        "- Use the following example as a guide:\n",
        "\n",
        "Example Format:\n",
        "\n",
        "{{\n",
        "    \"title\": \"What is Git and GitHub and Why It Is Used?\",\n",
        "    \"langCode\": \"en\",\n",
        "    \"dialogue\": [\n",
        "        {{\"male\": \"I am so excited to be here today!, excited\"}},\n",
        "        {{\"female\": \"That makes me really happy!, happy\"}},\n",
        "        ...\n",
        "    ]\n",
        "}}\n",
        "\n",
        "Now, generate the response for the question: \"{que}\" in 10 lines\n",
        ".\n",
        "\"\"\"\n",
        "    res = llm.invoke(prompt)\n",
        "    raw_content = res.content\n",
        "\n",
        "    try:\n",
        "        formatted_content = json.loads(raw_content)\n",
        "\n",
        "        required_keys = [\"title\", \"langCode\", \"dialogue\"]\n",
        "        if not all(key in formatted_content for key in required_keys):\n",
        "            print(\"Error: Generated content is missing required fields.\")\n",
        "            print(\"Generated Content:\", json.dumps(formatted_content, indent=4))\n",
        "            exit()\n",
        "        data = formatted_content[\"dialogue\"]\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"Error decoding JSON from LLM response:\", str(e))\n",
        "        print(\"Raw Response Content:\", raw_content)\n",
        "\n",
        "    voices = {\"male\": \"en-US-JasonNeural\", \"female\": \"en-US-JessaNeural\"}\n",
        "\n",
        "    output_dir = \"output_directory\"  # Specify your output directory\n",
        "    final_output_file = \"final_output.wav\"\n",
        "    print(data)\n",
        "    final_audio_path = await generate_dialogue_audio(data, voices, output_dir, final_output_file)\n",
        "    print(f\"Final audio saved at {final_audio_path}\")\n",
        "\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0HdPMLUk7SN",
        "outputId": "388f0bc1-c645-492c-afa5-4cf8be113423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is python\n",
            "[{'male': \"Hello, I'm here to talk about Python, cheerful\"}, {'female': \"I'm excited to learn about it, let's get started!, excited\"}, {'male': 'Python is a high-level programming language, calm'}, {'female': \"That's right, it's easy to learn and understand, friendly\"}, {'male': 'It was created in the late 1980s by Guido van Rossum, serious'}, {'female': \"And it's now one of the most popular languages, cheerful\"}, {'male': 'Python is used for web development, data analysis, and more, enthusiastic'}, {'female': \"It's also used in artificial intelligence and machine learning, gentle\"}, {'male': 'The syntax is simple and easy to read, making it perfect for beginners, hopeful'}, {'female': \"So, if you're interested in programming, Python is a great place to start!, excited\"}]\n",
            "Final audio saved at final_output.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Added Features\n",
        "->user can choose:\n",
        "1.  language\n",
        "2.  Time Length\n",
        "3. degree(softer or stornger voice range between 0.01 to 2)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ip1f5GfRlViO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import os\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "from pydub import AudioSegment\n",
        "from langchain_groq import ChatGroq\n",
        "import json\n",
        "\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key='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',\n",
        "    model_name=\"llama-3.1-70b-versatile\"\n",
        ")\n",
        "\n",
        "async def text_to_speech_async(ssml, output_wav_file):\n",
        "    \"\"\"Asynchronously converts SSML to speech and saves it to a file.\"\"\"\n",
        "    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)\n",
        "\n",
        "    os.makedirs(os.path.dirname(output_wav_file), exist_ok=True)\n",
        "\n",
        "    audio_config = speechsdk.audio.AudioOutputConfig(filename=output_wav_file)\n",
        "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
        "\n",
        "    result_future = synthesizer.speak_ssml_async(ssml)\n",
        "\n",
        "    result = await asyncio.to_thread(result_future.get)\n",
        "\n",
        "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
        "        return output_wav_file\n",
        "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
        "        cancellation_details = result.cancellation_details\n",
        "        raise Exception(f\"Speech synthesis canceled: {cancellation_details.reason} - {cancellation_details.error_details}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "async def generate_dialogue_audio(dialogue, voices, output_dir, final_output_file,s_degree):\n",
        "    audio_files = []\n",
        "\n",
        "    tasks = []\n",
        "\n",
        "    for idx, line in enumerate(dialogue):\n",
        "      for speaker, content in line.items():\n",
        "        text, emotion = content.rsplit(\",\", 1) if \",\" in content else (content, \"neutral\")\n",
        "        emotion = emotion.strip()\n",
        "\n",
        "        if speaker == \"male\":\n",
        "            voice = voices[\"male\"]\n",
        "        else:\n",
        "            voice = voices[\"female\"]\n",
        "        ssml = f\"\"\"\n",
        "            <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"http://www.w3.org/2001/mstts\" xml:lang=\"en-US\">\n",
        "                <voice name=\"{voice}\">\n",
        "                    <mstts:express-as style=\"{emotion}\" styledegree=\"2\">\n",
        "                        {text}\n",
        "                    </mstts:express-as>\n",
        "                </voice>\n",
        "            </speak>\n",
        "            \"\"\"\n",
        "\n",
        "        temp_audio_file = os.path.join(output_dir, f\"temp_dialogue_{idx+1}_{speaker}.wav\")\n",
        "        tasks.append(text_to_speech_async(ssml, temp_audio_file))\n",
        "\n",
        "    # Wait for all tasks to complete and get their results\n",
        "    audio_files = await asyncio.gather(*tasks)\n",
        "\n",
        "    final_audio_path = combine_audio_files(audio_files, final_output_file)\n",
        "\n",
        "\n",
        "    for temp_audio_file in audio_files:\n",
        "        os.remove(temp_audio_file)\n",
        "\n",
        "    return final_audio_path\n",
        "\n",
        "\n",
        "def combine_audio_files(audio_files, final_output_file):\n",
        "    \"\"\"Combines the individual audio files into a final output file.\"\"\"\n",
        "    combined_audio = AudioSegment.empty()\n",
        "    for audio_file in audio_files:\n",
        "        audio_segment = AudioSegment.from_wav(audio_file)\n",
        "        combined_audio += audio_segment\n",
        "\n",
        "    combined_audio.export(final_output_file, format=\"wav\")\n",
        "    return final_output_file\n",
        "\n",
        "\n",
        "async def main():\n",
        "    que = input()\n",
        "    langCode = input(\"enter langcode:\")\n",
        "    time_r = input(\"enter time range in seconds:\")\n",
        "    num = int(time_r)//5\n",
        "    s_degree = input(\"enter the degree\")\n",
        "    prompt = f\"\"\"\n",
        "You are an AI model designed to generate podcast content.\n",
        "- Please provide an answer to the following question : \"{que}\",with given langCode\"{langCode}\" in the specified JSON format.\n",
        "- Ensure the response includes a title, language code, and dialogue with multiple participants also with emotion which best suites for dialouge at end of each dialogue seperated by ',' with dialouge.\n",
        "- Only use one of the following emotions: advertisement_upbeat, affectionate, angry, assistant, calm, chat, cheerful, customerservice, depressed, disgruntled, documentary-narration, embarrassed, empathetic, envious, excited, fearful, friendly, gentle, hopeful, lyrical, narration-professional, narration-relaxed, newscast, newscast-casual, newscast-formal, poetry-reading, sad, serious, shouting, sports_commentary, sports_commentary_excited, whispering, terrified, unfriendly.\n",
        "- Make it engaging, informative, and structured.\n",
        "- Use the following example as a guide:\n",
        "\n",
        "Example Format:\n",
        "\n",
        "{{\n",
        "    \"title\": \"What is Git and GitHub and Why It Is Used?\",\n",
        "    \"langCode\": \"en\",\n",
        "    \"dialogue\": [\n",
        "        {{\"male\": \"Todays podcast is about git hub and git, excited\"}},\n",
        "        {{\"female\": \"That makes me really happy!, happy\"}},\n",
        "        ...\n",
        "    ]\n",
        "}}\n",
        "\n",
        "Now, generate the response for the question: \"{que}\" in {num} lines\n",
        ".\n",
        "\"\"\"\n",
        "    res = llm.invoke(prompt)\n",
        "    raw_content = res.content\n",
        "\n",
        "    try:\n",
        "        formatted_content = json.loads(raw_content)\n",
        "\n",
        "        required_keys = [\"title\", \"langCode\", \"dialogue\"]\n",
        "        if not all(key in formatted_content for key in required_keys):\n",
        "            print(\"Error: Generated content is missing required fields.\")\n",
        "            print(\"Generated Content:\", json.dumps(formatted_content, indent=4))\n",
        "            exit()\n",
        "        data = formatted_content[\"dialogue\"]\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"Error decoding JSON from LLM response:\", str(e))\n",
        "        print(\"Raw Response Content:\", raw_content)\n",
        "\n",
        "    voices1 = {\n",
        "    \"en\": {\"male\": \"en-US-GuyNeural\", \"female\": \"en-US-JennyNeural\"},\n",
        "    \"te\": {\"male\": \"te-IN-MohanNeural\", \"female\": \"te-IN-ShrutiNeural\"},\n",
        "    \"hi\": {\"male\": \"hi-IN-AmitNeural\", \"female\": \"hi-IN-SumanNeural\"},\n",
        "    \"es\": {\"male\": \"es-ES-ÁngelNeural\", \"female\": \"es-ES-ElenaNeural\"},\n",
        "    \"fr\": {\"male\": \"fr-FR-HenriNeural\", \"female\": \"fr-FR-DeniseNeural\"},\n",
        "    \"de\": {\"male\": \"de-DE-KlausNeural\", \"female\": \"de-DE-KatjaNeural\"},\n",
        "    \"it\": {\"male\": \"it-IT-GiorgioNeural\", \"female\": \"it-IT-ElsaNeural\"},\n",
        "    \"ja\": {\"male\": \"ja-JP-HiroshiNeural\", \"female\": \"ja-JP-NatsukiNeural\"},\n",
        "    \"ko\": {\"male\": \"ko-KR-JayNeural\", \"female\": \"ko-KR-SunHiNeural\"},\n",
        "    \"pt\": {\"male\": \"pt-BR-AntonioNeural\", \"female\": \"pt-BR-AmandaNeural\"},\n",
        "    \"zh\": {\"male\": \"zh-CN-XiaoxiaoNeural\", \"female\": \"zh-CN-YunxiNeural\"},\n",
        "    \"ar\": {\"male\": \"ar-EG-HossamNeural\", \"female\": \"ar-EG-SalmaNeural\"},\n",
        "    \"pl\": {\"male\": \"pl-PL-RafalNeural\", \"female\": \"pl-PL-KarolinaNeural\"},\n",
        "    \"tr\": {\"male\": \"tr-TR-BerkNeural\", \"female\": \"tr-TR-BirceNeural\"},\n",
        "    \"sv\": {\"male\": \"sv-SE-AlvaNeural\", \"female\": \"sv-SE-IlseNeural\"},\n",
        "    \"ru\": {\"male\": \"ru-RU-DmitryNeural\", \"female\": \"ru-RU-TatyanaNeural\"},\n",
        "    \"nl\": {\"male\": \"nl-NL-KrisNeural\", \"female\": \"nl-NL-LauraNeural\"},\n",
        "    \"da\": {\"male\": \"da-DK-MortenNeural\", \"female\": \"da-DK-KarenNeural\"},\n",
        "    \"fi\": {\"male\": \"fi-FI-KalleNeural\", \"female\": \"fi-FI-KaisaNeural\"},\n",
        "    \"no\": {\"male\": \"no-NO-OleNeural\", \"female\": \"no-NO-SofieNeural\"},\n",
        "    \"cs\": {\"male\": \"cs-CZ-VojtaNeural\", \"female\": \"cs-CZ-LuciaNeural\"},\n",
        "    \"sk\": {\"male\": \"sk-SK-MilanNeural\", \"female\": \"sk-SK-SofiaNeural\"},\n",
        "    \"he\": {\"male\": \"he-IL-RonenNeural\", \"female\": \"he-IL-NoaNeural\"},\n",
        "    \"ro\": {\"male\": \"ro-RO-MateiNeural\", \"female\": \"ro-RO-LaviniaNeural\"},\n",
        "    \"bn\": {\"male\": \"bn-IN-RaviNeural\", \"female\": \"bn-IN-KavitaNeural\"},\n",
        "    \"ms\": {\"male\": \"ms-MY-MathewsNeural\", \"female\": \"ms-MY-SitiNeural\"},\n",
        "    \"ta\": {\"male\": \"ta-IN-KamalNeural\", \"female\": \"ta-IN-SitaraNeural\"},\n",
        "    \"vi\": {\"male\": \"vi-VN-HoaiAnNeural\", \"female\": \"vi-VN-PhuongNeural\"},\n",
        "    \"th\": {\"male\": \"th-TH-ThanetNeural\", \"female\": \"th-TH-FahNeural\"},\n",
        "    \"el\": {\"male\": \"el-GR-GiorgosNeural\", \"female\": \"el-GR-KaterinaNeural\"},\n",
        "    \"hu\": {\"male\": \"hu-HU-BalazsNeural\", \"female\": \"hu-HU-ZsuzsaNeural\"},\n",
        "    \"uk\": {\"male\": \"uk-UA-YevhenNeural\", \"female\": \"uk-UA-OlenaNeural\"},\n",
        "    \"ms\": {\"male\": \"ms-MY-MathewsNeural\", \"female\": \"ms-MY-SitiNeural\"},\n",
        "    \"sq\": {\"male\": \"sq-AL-ArdianNeural\", \"female\": \"sq-AL-DafinaNeural\"},\n",
        "    \"hr\": {\"male\": \"hr-HR-DamirNeural\", \"female\": \"hr-HR-MajaNeural\"},\n",
        "    \"sr\": {\"male\": \"sr-RS-JovanNeural\", \"female\": \"sr-RS-AnaNeural\"},\n",
        "    \"lt\": {\"male\": \"lt-LT-MindaugasNeural\", \"female\": \"lt-LT-MildaNeural\"},\n",
        "    \"et\": {\"male\": \"et-EE-JaanNeural\", \"female\": \"et-EE-KaiaNeural\"},\n",
        "    \"lv\": {\"male\": \"lv-LV-MatisNeural\", \"female\": \"lv-LV-KatrinaNeural\"},\n",
        "    \"bg\": {\"male\": \"bg-BG-DimitraNeural\", \"female\": \"bg-BG-EvgeniaNeural\"},\n",
        "    \"zh-HK\": {\"male\": \"zh-HK-HarleyNeural\", \"female\": \"zh-HK-YunjieNeural\"},\n",
        "    \"zh-TW\": {\"male\": \"zh-TW-YuYunNeural\", \"female\": \"zh-TW-YuYingNeural\"},\n",
        "    \"ja-JP\": {\"male\": \"ja-JP-HiroshiNeural\", \"female\": \"ja-JP-NatsukiNeural\"},\n",
        "    \"ko-KR\": {\"male\": \"ko-KR-JayNeural\", \"female\": \"ko-KR-SunHiNeural\"},\n",
        "    \"fi-FI\": {\"male\": \"fi-FI-KalleNeural\", \"female\": \"fi-FI-KaisaNeural\"},\n",
        "    # Add more languages and voices as needed\n",
        "\n",
        "}\n",
        "\n",
        "    voices = voices1[langCode]\n",
        "\n",
        "    output_dir = \"output_directory\"\n",
        "    final_output_file = \"final_output.wav\"\n",
        "    print(data)\n",
        "    final_audio_path = await generate_dialogue_audio(data, voices, output_dir, final_output_file,s_degree)\n",
        "    print(f\"Final audio saved at {final_audio_path}\")\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za5w-qgdZVw8",
        "outputId": "c8beba76-c29d-4d3c-ecce-80813b514372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "java\n",
            "enter langcode:en\n",
            "enter time range in seconds:50\n",
            "enter the degree0.01\n",
            "[{'male': \"Hello and welcome to our podcast, today we're going to talk about Java, cheerful\"}, {'female': \"I'm excited to learn about Java, it's such a popular programming language, excited\"}, {'male': 'Yes, Java is widely used for developing large-scale applications, calm'}, {'female': \"That's right, and it's also known for its platform independence, friendly\"}, {'male': \"Java is an object-oriented language, and it's relatively easy to learn, gentle\"}, {'female': \"I've heard that Java is used in Android app development, is that true?, curious\"}, {'male': 'Yes, Java is used for developing Android apps, as well as web applications, serious'}, {'female': \"That's really cool, I'm looking forward to learning more about Java, hopeful\"}, {'male': \"We'll be covering the basics of Java, including variables, data types, and control structures, calm\"}, {'female': \"I'm ready to get started, let's dive into the world of Java, excited\"}]\n",
            "Final audio saved at final_output.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sZaLzBx2nN_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X7nziXXTp9md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"en-IN\": {'male': 'en-IN-ArjunNeural', 'female': 'en-IN-AartiNeural'},\n",
        "\"en-GB\": {'male': 'en-GB-ThomasNeural', 'female': 'en-GB-MiaNeural'},\n",
        "\"en-US\": {'male': 'en-US-Steffan:DragonHDLatestNeural', 'female': 'en-US-Jenny:DragonHDLatestNeural'}\n",
        "\n",
        "\"en-US\":{\"male\": \"en-US-JasonNeural\", \"female\": \"en-US-JessaNeural\"},"
      ],
      "metadata": {
        "id": "85AWJKPlp9i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Availabaility of Voices"
      ],
      "metadata": {
        "id": "BP7RdZplqAJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azure.cognitiveservices.speech as speechsdk\n",
        "\n",
        " # Replace with your Azure Speech Service key\n",
        "SPEECH_KEY = \"7b21760a5b1b43b48db52c037c357844\"\n",
        "SPEECH_REGION = \"eastus\"\n",
        "\n",
        "# Create speech configuration\n",
        "speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)\n",
        "\n",
        "# Initialize SpeechSynthesizer\n",
        "synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
        "\n",
        "# Retrieve available voices\n",
        "voices = synthesizer.get_voices_async().get()\n",
        "\n",
        "# Dictionary to store languages and voice names\n",
        "language_voices = {}\n",
        "\n",
        "# Iterate through voices and populate the dictionary\n",
        "for voice in voices.voices:\n",
        "    language = voice.locale\n",
        "    gender = voice.gender.name.lower()  # Get gender as \"male\" or \"female\"\n",
        "\n",
        "    if language not in language_voices:\n",
        "        language_voices[language] = {\"male\": None, \"female\": None}\n",
        "\n",
        "    # Assign male or female voice to the dictionary\n",
        "    language_voices[language][gender] = voice.short_name\n",
        "print(len(language_voices))\n",
        "# Display the dictionary\n",
        "for lang, genders in language_voices.items():\n",
        "    print(f'\"{lang}\": {genders},')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-sCEscZp9g1",
        "outputId": "2c08598b-c126-4066-e9d4-382f34674e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "154\n",
            "\"af-ZA\": {'male': 'af-ZA-WillemNeural', 'female': 'af-ZA-AdriNeural'},\n",
            "\"am-ET\": {'male': 'am-ET-AmehaNeural', 'female': 'am-ET-MekdesNeural'},\n",
            "\"ar-AE\": {'male': 'ar-AE-HamdanNeural', 'female': 'ar-AE-FatimaNeural'},\n",
            "\"ar-BH\": {'male': 'ar-BH-AliNeural', 'female': 'ar-BH-LailaNeural'},\n",
            "\"ar-DZ\": {'male': 'ar-DZ-IsmaelNeural', 'female': 'ar-DZ-AminaNeural'},\n",
            "\"ar-EG\": {'male': 'ar-EG-ShakirNeural', 'female': 'ar-EG-SalmaNeural'},\n",
            "\"ar-IQ\": {'male': 'ar-IQ-BasselNeural', 'female': 'ar-IQ-RanaNeural'},\n",
            "\"ar-JO\": {'male': 'ar-JO-TaimNeural', 'female': 'ar-JO-SanaNeural'},\n",
            "\"ar-KW\": {'male': 'ar-KW-FahedNeural', 'female': 'ar-KW-NouraNeural'},\n",
            "\"ar-LB\": {'male': 'ar-LB-RamiNeural', 'female': 'ar-LB-LaylaNeural'},\n",
            "\"ar-LY\": {'male': 'ar-LY-OmarNeural', 'female': 'ar-LY-ImanNeural'},\n",
            "\"ar-MA\": {'male': 'ar-MA-JamalNeural', 'female': 'ar-MA-MounaNeural'},\n",
            "\"ar-OM\": {'male': 'ar-OM-AbdullahNeural', 'female': 'ar-OM-AyshaNeural'},\n",
            "\"ar-QA\": {'male': 'ar-QA-MoazNeural', 'female': 'ar-QA-AmalNeural'},\n",
            "\"ar-SA\": {'male': 'ar-SA-HamedNeural', 'female': 'ar-SA-ZariyahNeural'},\n",
            "\"ar-SY\": {'male': 'ar-SY-LaithNeural', 'female': 'ar-SY-AmanyNeural'},\n",
            "\"ar-TN\": {'male': 'ar-TN-HediNeural', 'female': 'ar-TN-ReemNeural'},\n",
            "\"ar-YE\": {'male': 'ar-YE-SalehNeural', 'female': 'ar-YE-MaryamNeural'},\n",
            "\"as-IN\": {'male': 'as-IN-PriyomNeural', 'female': 'as-IN-YashicaNeural'},\n",
            "\"az-AZ\": {'male': 'az-AZ-BabekNeural', 'female': 'az-AZ-BanuNeural'},\n",
            "\"bg-BG\": {'male': 'bg-BG-BorislavNeural', 'female': 'bg-BG-KalinaNeural'},\n",
            "\"bn-BD\": {'male': 'bn-BD-PradeepNeural', 'female': 'bn-BD-NabanitaNeural'},\n",
            "\"bn-IN\": {'male': 'bn-IN-BashkarNeural', 'female': 'bn-IN-TanishaaNeural'},\n",
            "\"bs-BA\": {'male': 'bs-BA-GoranNeural', 'female': 'bs-BA-VesnaNeural'},\n",
            "\"ca-ES\": {'male': 'ca-ES-EnricNeural', 'female': 'ca-ES-AlbaNeural'},\n",
            "\"cs-CZ\": {'male': 'cs-CZ-AntoninNeural', 'female': 'cs-CZ-VlastaNeural'},\n",
            "\"cy-GB\": {'male': 'cy-GB-AledNeural', 'female': 'cy-GB-NiaNeural'},\n",
            "\"da-DK\": {'male': 'da-DK-JeppeNeural', 'female': 'da-DK-ChristelNeural'},\n",
            "\"de-AT\": {'male': 'de-AT-JonasNeural', 'female': 'de-AT-IngridNeural'},\n",
            "\"de-CH\": {'male': 'de-CH-JanNeural', 'female': 'de-CH-LeniNeural'},\n",
            "\"de-DE\": {'male': 'de-DE-RalfNeural', 'female': 'de-DE-Seraphina:DragonHDLatestNeural'},\n",
            "\"el-GR\": {'male': 'el-GR-NestorasNeural', 'female': 'el-GR-AthinaNeural'},\n",
            "\"en-AU\": {'male': 'en-AU-TimNeural', 'female': 'en-AU-TinaNeural'},\n",
            "\"en-CA\": {'male': 'en-CA-LiamNeural', 'female': 'en-CA-ClaraNeural'},\n",
            "\"en-GB\": {'male': 'en-GB-ThomasNeural', 'female': 'en-GB-MiaNeural'},\n",
            "\"en-HK\": {'male': 'en-HK-SamNeural', 'female': 'en-HK-YanNeural'},\n",
            "\"en-IE\": {'male': 'en-IE-ConnorNeural', 'female': 'en-IE-EmilyNeural'},\n",
            "\"en-IN\": {'male': 'en-IN-ArjunNeural', 'female': 'en-IN-AartiNeural'},\n",
            "\"en-KE\": {'male': 'en-KE-ChilembaNeural', 'female': 'en-KE-AsiliaNeural'},\n",
            "\"en-NG\": {'male': 'en-NG-AbeoNeural', 'female': 'en-NG-EzinneNeural'},\n",
            "\"en-NZ\": {'male': 'en-NZ-MitchellNeural', 'female': 'en-NZ-MollyNeural'},\n",
            "\"en-PH\": {'male': 'en-PH-JamesNeural', 'female': 'en-PH-RosaNeural'},\n",
            "\"en-SG\": {'male': 'en-SG-WayneNeural', 'female': 'en-SG-LunaNeural'},\n",
            "\"en-TZ\": {'male': 'en-TZ-ElimuNeural', 'female': 'en-TZ-ImaniNeural'},\n",
            "\"en-US\": {'male': 'en-US-Steffan:DragonHDLatestNeural', 'female': 'en-US-Jenny:DragonHDLatestNeural', 'unknown': 'en-US-FableTurboMultilingualNeural'},\n",
            "\"en-ZA\": {'male': 'en-ZA-LukeNeural', 'female': 'en-ZA-LeahNeural'},\n",
            "\"es-AR\": {'male': 'es-AR-TomasNeural', 'female': 'es-AR-ElenaNeural'},\n",
            "\"es-BO\": {'male': 'es-BO-MarceloNeural', 'female': 'es-BO-SofiaNeural'},\n",
            "\"es-CL\": {'male': 'es-CL-LorenzoNeural', 'female': 'es-CL-CatalinaNeural'},\n",
            "\"es-CO\": {'male': 'es-CO-GonzaloNeural', 'female': 'es-CO-SalomeNeural'},\n",
            "\"es-CR\": {'male': 'es-CR-JuanNeural', 'female': 'es-CR-MariaNeural'},\n",
            "\"es-CU\": {'male': 'es-CU-ManuelNeural', 'female': 'es-CU-BelkysNeural'},\n",
            "\"es-DO\": {'male': 'es-DO-EmilioNeural', 'female': 'es-DO-RamonaNeural'},\n",
            "\"es-EC\": {'male': 'es-EC-LuisNeural', 'female': 'es-EC-AndreaNeural'},\n",
            "\"es-ES\": {'male': 'es-ES-TeoNeural', 'female': 'es-ES-XimenaNeural'},\n",
            "\"es-GQ\": {'male': 'es-GQ-JavierNeural', 'female': 'es-GQ-TeresaNeural'},\n",
            "\"es-GT\": {'male': 'es-GT-AndresNeural', 'female': 'es-GT-MartaNeural'},\n",
            "\"es-HN\": {'male': 'es-HN-CarlosNeural', 'female': 'es-HN-KarlaNeural'},\n",
            "\"es-MX\": {'male': 'es-MX-YagoNeural', 'female': 'es-MX-RenataNeural'},\n",
            "\"es-NI\": {'male': 'es-NI-FedericoNeural', 'female': 'es-NI-YolandaNeural'},\n",
            "\"es-PA\": {'male': 'es-PA-RobertoNeural', 'female': 'es-PA-MargaritaNeural'},\n",
            "\"es-PE\": {'male': 'es-PE-AlexNeural', 'female': 'es-PE-CamilaNeural'},\n",
            "\"es-PR\": {'male': 'es-PR-VictorNeural', 'female': 'es-PR-KarinaNeural'},\n",
            "\"es-PY\": {'male': 'es-PY-MarioNeural', 'female': 'es-PY-TaniaNeural'},\n",
            "\"es-SV\": {'male': 'es-SV-RodrigoNeural', 'female': 'es-SV-LorenaNeural'},\n",
            "\"es-US\": {'male': 'es-US-AlonsoNeural', 'female': 'es-US-PalomaNeural'},\n",
            "\"es-UY\": {'male': 'es-UY-MateoNeural', 'female': 'es-UY-ValentinaNeural'},\n",
            "\"es-VE\": {'male': 'es-VE-SebastianNeural', 'female': 'es-VE-PaolaNeural'},\n",
            "\"et-EE\": {'male': 'et-EE-KertNeural', 'female': 'et-EE-AnuNeural'},\n",
            "\"eu-ES\": {'male': 'eu-ES-AnderNeural', 'female': 'eu-ES-AinhoaNeural'},\n",
            "\"fa-IR\": {'male': 'fa-IR-FaridNeural', 'female': 'fa-IR-DilaraNeural'},\n",
            "\"fi-FI\": {'male': 'fi-FI-HarriNeural', 'female': 'fi-FI-NooraNeural'},\n",
            "\"fil-PH\": {'male': 'fil-PH-AngeloNeural', 'female': 'fil-PH-BlessicaNeural'},\n",
            "\"fr-BE\": {'male': 'fr-BE-GerardNeural', 'female': 'fr-BE-CharlineNeural'},\n",
            "\"fr-CA\": {'male': 'fr-CA-ThierryNeural', 'female': 'fr-CA-SylvieNeural'},\n",
            "\"fr-CH\": {'male': 'fr-CH-FabriceNeural', 'female': 'fr-CH-ArianeNeural'},\n",
            "\"fr-FR\": {'male': 'fr-FR-YvesNeural', 'female': 'fr-FR-YvetteNeural'},\n",
            "\"ga-IE\": {'male': 'ga-IE-ColmNeural', 'female': 'ga-IE-OrlaNeural'},\n",
            "\"gl-ES\": {'male': 'gl-ES-RoiNeural', 'female': 'gl-ES-SabelaNeural'},\n",
            "\"gu-IN\": {'male': 'gu-IN-NiranjanNeural', 'female': 'gu-IN-DhwaniNeural'},\n",
            "\"he-IL\": {'male': 'he-IL-AvriNeural', 'female': 'he-IL-HilaNeural'},\n",
            "\"hi-IN\": {'male': 'hi-IN-ArjunNeural', 'female': 'hi-IN-AartiNeural'},\n",
            "\"hr-HR\": {'male': 'hr-HR-SreckoNeural', 'female': 'hr-HR-GabrijelaNeural'},\n",
            "\"hu-HU\": {'male': 'hu-HU-TamasNeural', 'female': 'hu-HU-NoemiNeural'},\n",
            "\"hy-AM\": {'male': 'hy-AM-HaykNeural', 'female': 'hy-AM-AnahitNeural'},\n",
            "\"id-ID\": {'male': 'id-ID-ArdiNeural', 'female': 'id-ID-GadisNeural'},\n",
            "\"is-IS\": {'male': 'is-IS-GunnarNeural', 'female': 'is-IS-GudrunNeural'},\n",
            "\"it-IT\": {'male': 'it-IT-RinaldoNeural', 'female': 'it-IT-PierinaNeural'},\n",
            "\"iu-Cans-CA\": {'male': 'iu-Cans-CA-TaqqiqNeural', 'female': 'iu-Cans-CA-SiqiniqNeural'},\n",
            "\"iu-Latn-CA\": {'male': 'iu-Latn-CA-TaqqiqNeural', 'female': 'iu-Latn-CA-SiqiniqNeural'},\n",
            "\"ja-JP\": {'male': 'ja-JP-Masaru:DragonHDLatestNeural', 'female': 'ja-JP-ShioriNeural'},\n",
            "\"jv-ID\": {'male': 'jv-ID-DimasNeural', 'female': 'jv-ID-SitiNeural'},\n",
            "\"ka-GE\": {'male': 'ka-GE-GiorgiNeural', 'female': 'ka-GE-EkaNeural'},\n",
            "\"kk-KZ\": {'male': 'kk-KZ-DauletNeural', 'female': 'kk-KZ-AigulNeural'},\n",
            "\"km-KH\": {'male': 'km-KH-PisethNeural', 'female': 'km-KH-SreymomNeural'},\n",
            "\"kn-IN\": {'male': 'kn-IN-GaganNeural', 'female': 'kn-IN-SapnaNeural'},\n",
            "\"ko-KR\": {'male': 'ko-KR-HyunsuNeural', 'female': 'ko-KR-YuJinNeural'},\n",
            "\"lo-LA\": {'male': 'lo-LA-ChanthavongNeural', 'female': 'lo-LA-KeomanyNeural'},\n",
            "\"lt-LT\": {'male': 'lt-LT-LeonasNeural', 'female': 'lt-LT-OnaNeural'},\n",
            "\"lv-LV\": {'male': 'lv-LV-NilsNeural', 'female': 'lv-LV-EveritaNeural'},\n",
            "\"mk-MK\": {'male': 'mk-MK-AleksandarNeural', 'female': 'mk-MK-MarijaNeural'},\n",
            "\"ml-IN\": {'male': 'ml-IN-MidhunNeural', 'female': 'ml-IN-SobhanaNeural'},\n",
            "\"mn-MN\": {'male': 'mn-MN-BataaNeural', 'female': 'mn-MN-YesuiNeural'},\n",
            "\"mr-IN\": {'male': 'mr-IN-ManoharNeural', 'female': 'mr-IN-AarohiNeural'},\n",
            "\"ms-MY\": {'male': 'ms-MY-OsmanNeural', 'female': 'ms-MY-YasminNeural'},\n",
            "\"mt-MT\": {'male': 'mt-MT-JosephNeural', 'female': 'mt-MT-GraceNeural'},\n",
            "\"my-MM\": {'male': 'my-MM-ThihaNeural', 'female': 'my-MM-NilarNeural'},\n",
            "\"nb-NO\": {'male': 'nb-NO-FinnNeural', 'female': 'nb-NO-IselinNeural'},\n",
            "\"ne-NP\": {'male': 'ne-NP-SagarNeural', 'female': 'ne-NP-HemkalaNeural'},\n",
            "\"nl-BE\": {'male': 'nl-BE-ArnaudNeural', 'female': 'nl-BE-DenaNeural'},\n",
            "\"nl-NL\": {'male': 'nl-NL-MaartenNeural', 'female': 'nl-NL-ColetteNeural'},\n",
            "\"or-IN\": {'male': 'or-IN-SukantNeural', 'female': 'or-IN-SubhasiniNeural'},\n",
            "\"pa-IN\": {'male': 'pa-IN-OjasNeural', 'female': 'pa-IN-VaaniNeural'},\n",
            "\"pl-PL\": {'male': 'pl-PL-MarekNeural', 'female': 'pl-PL-ZofiaNeural'},\n",
            "\"ps-AF\": {'male': 'ps-AF-GulNawazNeural', 'female': 'ps-AF-LatifaNeural'},\n",
            "\"pt-BR\": {'male': 'pt-BR-ValerioNeural', 'female': 'pt-BR-YaraNeural'},\n",
            "\"pt-PT\": {'male': 'pt-PT-DuarteNeural', 'female': 'pt-PT-FernandaNeural'},\n",
            "\"ro-RO\": {'male': 'ro-RO-EmilNeural', 'female': 'ro-RO-AlinaNeural'},\n",
            "\"ru-RU\": {'male': 'ru-RU-DmitryNeural', 'female': 'ru-RU-DariyaNeural'},\n",
            "\"si-LK\": {'male': 'si-LK-SameeraNeural', 'female': 'si-LK-ThiliniNeural'},\n",
            "\"sk-SK\": {'male': 'sk-SK-LukasNeural', 'female': 'sk-SK-ViktoriaNeural'},\n",
            "\"sl-SI\": {'male': 'sl-SI-RokNeural', 'female': 'sl-SI-PetraNeural'},\n",
            "\"so-SO\": {'male': 'so-SO-MuuseNeural', 'female': 'so-SO-UbaxNeural'},\n",
            "\"sq-AL\": {'male': 'sq-AL-IlirNeural', 'female': 'sq-AL-AnilaNeural'},\n",
            "\"sr-Latn-RS\": {'male': 'sr-Latn-RS-NicholasNeural', 'female': 'sr-Latn-RS-SophieNeural'},\n",
            "\"sr-RS\": {'male': 'sr-RS-NicholasNeural', 'female': 'sr-RS-SophieNeural'},\n",
            "\"su-ID\": {'male': 'su-ID-JajangNeural', 'female': 'su-ID-TutiNeural'},\n",
            "\"sv-SE\": {'male': 'sv-SE-MattiasNeural', 'female': 'sv-SE-HilleviNeural'},\n",
            "\"sw-KE\": {'male': 'sw-KE-RafikiNeural', 'female': 'sw-KE-ZuriNeural'},\n",
            "\"sw-TZ\": {'male': 'sw-TZ-DaudiNeural', 'female': 'sw-TZ-RehemaNeural'},\n",
            "\"ta-IN\": {'male': 'ta-IN-ValluvarNeural', 'female': 'ta-IN-PallaviNeural'},\n",
            "\"ta-LK\": {'male': 'ta-LK-KumarNeural', 'female': 'ta-LK-SaranyaNeural'},\n",
            "\"ta-MY\": {'male': 'ta-MY-SuryaNeural', 'female': 'ta-MY-KaniNeural'},\n",
            "\"ta-SG\": {'male': 'ta-SG-AnbuNeural', 'female': 'ta-SG-VenbaNeural'},\n",
            "\"te-IN\": {'male': 'te-IN-MohanNeural', 'female': 'te-IN-ShrutiNeural'},\n",
            "\"th-TH\": {'male': 'th-TH-NiwatNeural', 'female': 'th-TH-AcharaNeural'},\n",
            "\"tr-TR\": {'male': 'tr-TR-AhmetNeural', 'female': 'tr-TR-EmelNeural'},\n",
            "\"uk-UA\": {'male': 'uk-UA-OstapNeural', 'female': 'uk-UA-PolinaNeural'},\n",
            "\"ur-IN\": {'male': 'ur-IN-SalmanNeural', 'female': 'ur-IN-GulNeural'},\n",
            "\"ur-PK\": {'male': 'ur-PK-AsadNeural', 'female': 'ur-PK-UzmaNeural'},\n",
            "\"uz-UZ\": {'male': 'uz-UZ-SardorNeural', 'female': 'uz-UZ-MadinaNeural'},\n",
            "\"vi-VN\": {'male': 'vi-VN-NamMinhNeural', 'female': 'vi-VN-HoaiMyNeural'},\n",
            "\"wuu-CN\": {'male': 'wuu-CN-YunzheNeural', 'female': 'wuu-CN-XiaotongNeural'},\n",
            "\"yue-CN\": {'male': 'yue-CN-YunSongNeural', 'female': 'yue-CN-XiaoMinNeural'},\n",
            "\"zh-CN\": {'male': 'zh-CN-YunxiaoMultilingualNeural', 'female': 'zh-CN-Xiaochen:DragonHDLatestNeural'},\n",
            "\"zh-CN-guangxi\": {'male': 'zh-CN-guangxi-YunqiNeural', 'female': None},\n",
            "\"zh-CN-henan\": {'male': 'zh-CN-henan-YundengNeural', 'female': None},\n",
            "\"zh-CN-liaoning\": {'male': 'zh-CN-liaoning-YunbiaoNeural', 'female': 'zh-CN-liaoning-XiaobeiNeural'},\n",
            "\"zh-CN-shaanxi\": {'male': None, 'female': 'zh-CN-shaanxi-XiaoniNeural'},\n",
            "\"zh-CN-shandong\": {'male': 'zh-CN-shandong-YunxiangNeural', 'female': None},\n",
            "\"zh-CN-sichuan\": {'male': 'zh-CN-sichuan-YunxiNeural', 'female': None},\n",
            "\"zh-HK\": {'male': 'zh-HK-WanLungNeural', 'female': 'zh-HK-HiuGaaiNeural'},\n",
            "\"zh-TW\": {'male': 'zh-TW-YunJheNeural', 'female': 'zh-TW-HsiaoYuNeural'},\n",
            "\"zu-ZA\": {'male': 'zu-ZA-ThembaNeural', 'female': 'zu-ZA-ThandoNeural'},\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cuu-YbNwp-Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9tlh437nXtGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YYlaFolXtCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOR en-US,en-IN,en-GB"
      ],
      "metadata": {
        "id": "qmdSbz7MaHq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import os\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "from pydub import AudioSegment\n",
        "from langchain_groq import ChatGroq\n",
        "import json\n",
        "\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key='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',\n",
        "    model_name=\"llama-3.1-70b-versatile\"\n",
        ")\n",
        "\n",
        "async def text_to_speech_async(ssml, output_wav_file):\n",
        "    \"\"\"Asynchronously converts SSML to speech and saves it to a file.\"\"\"\n",
        "    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)\n",
        "\n",
        "    os.makedirs(os.path.dirname(output_wav_file), exist_ok=True)\n",
        "\n",
        "    audio_config = speechsdk.audio.AudioOutputConfig(filename=output_wav_file)\n",
        "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
        "\n",
        "    result_future = synthesizer.speak_ssml_async(ssml)\n",
        "\n",
        "    result = await asyncio.to_thread(result_future.get)\n",
        "\n",
        "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
        "        return output_wav_file\n",
        "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
        "        cancellation_details = result.cancellation_details\n",
        "        raise Exception(f\"Speech synthesis canceled: {cancellation_details.reason} - {cancellation_details.error_details}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "async def generate_dialogue_audio(dialogue, voices, output_dir, final_output_file,s_degree):\n",
        "    audio_files = []\n",
        "\n",
        "    tasks = []\n",
        "\n",
        "    for idx, line in enumerate(dialogue):\n",
        "      for speaker, content in line.items():\n",
        "        text, emotion = content.rsplit(\",\", 1) if \",\" in content else (content, \"neutral\")\n",
        "        emotion = emotion.strip()\n",
        "\n",
        "        if speaker == \"male\":\n",
        "            voice = voices[\"male\"]\n",
        "        else:\n",
        "            voice = voices[\"female\"]\n",
        "        ssml = f\"\"\"\n",
        "            <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"http://www.w3.org/2001/mstts\" xml:lang=\"en-US\">\n",
        "                <voice name=\"{voice}\">\n",
        "                    <mstts:express-as style=\"{emotion}\" styledegree=\"2\">\n",
        "                        {text}\n",
        "                    </mstts:express-as>\n",
        "                </voice>\n",
        "            </speak>\n",
        "            \"\"\"\n",
        "\n",
        "        temp_audio_file = os.path.join(output_dir, f\"temp_dialogue_{idx+1}_{speaker}.wav\")\n",
        "        tasks.append(text_to_speech_async(ssml, temp_audio_file))\n",
        "\n",
        "    # Wait for all tasks to complete and get their results\n",
        "    audio_files = await asyncio.gather(*tasks)\n",
        "\n",
        "    final_audio_path = combine_audio_files(audio_files, final_output_file)\n",
        "\n",
        "\n",
        "    for temp_audio_file in audio_files:\n",
        "        os.remove(temp_audio_file)\n",
        "\n",
        "    return final_audio_path\n",
        "\n",
        "\n",
        "def combine_audio_files(audio_files, final_output_file):\n",
        "    \"\"\"Combines the individual audio files into a final output file.\"\"\"\n",
        "    combined_audio = AudioSegment.empty()\n",
        "    for audio_file in audio_files:\n",
        "        audio_segment = AudioSegment.from_wav(audio_file)\n",
        "        combined_audio += audio_segment\n",
        "\n",
        "    combined_audio.export(final_output_file, format=\"wav\")\n",
        "    return final_output_file\n",
        "\n",
        "\n",
        "async def main():\n",
        "    que = input()\n",
        "    langCode = input(\"enter langcode:\")\n",
        "    time_r = input(\"enter time range in seconds:\")\n",
        "    num = int(time_r)//5\n",
        "    s_degree = input(\"enter the degree\")\n",
        "    prompt = f\"\"\"\n",
        "You are an AI model designed to generate podcast content.\n",
        "- Please provide a podcast script to the following question : \"{que}\",with given langCode\"{langCode}\" in the specified JSON format.\n",
        "- Ensure the response includes a title, language code, and dialogue with multiple participants also with emotion which best suites for dialouge at end of each dialogue seperated\n",
        " by ',' with dialouge.\n",
        "- Only use one of the following emotions: advertisement_upbeat, affectionate, angry, assistant, calm, chat, cheerful, customerservice, depressed, disgruntled, documentary-narration,\n",
        " embarrassed, empathetic, envious, excited, fearful, friendly, gentle, hopeful, lyrical, narration-professional, narration-relaxed, newscast, newscast-casual, newscast-formal,\n",
        " poetry-reading, sad, serious, shouting, sports_commentary, sports_commentary_excited, whispering, terrified, unfriendly.\n",
        "- Make it engaging, informative, and structured.\n",
        "- Use the following example as a guide:\n",
        "\n",
        "Example Format:\n",
        "\n",
        "{{\n",
        "    \"title\": \"What is Git and GitHub and Why It Is Used?\",\n",
        "    \"langCode\": \"en\",\n",
        "    \"dialogue\": [\n",
        "        {{\"male\": \"Todays podcast is about git hub and git, excited\"}},\n",
        "        {{\"female\": \"That makes me really happy!, happy\"}},\n",
        "        ...\n",
        "    ]\n",
        "}}\n",
        "\n",
        "Now, generate the response for the question: \"{que}\" in {num} lines\n",
        ".\n",
        "\"\"\"\n",
        "    res = llm.invoke(prompt)\n",
        "    raw_content = res.content\n",
        "\n",
        "    try:\n",
        "        formatted_content = json.loads(raw_content)\n",
        "\n",
        "        required_keys = [\"title\", \"langCode\", \"dialogue\"]\n",
        "        if not all(key in formatted_content for key in required_keys):\n",
        "            print(\"Error: Generated content is missing required fields.\")\n",
        "            print(\"Generated Content:\", json.dumps(formatted_content, indent=4))\n",
        "            exit()\n",
        "        data = formatted_content[\"dialogue\"]\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"Error decoding JSON from LLM response:\", str(e))\n",
        "        print(\"Raw Response Content:\", raw_content)\n",
        "\n",
        "    voices1 = {\n",
        "    \"en-IN\": {'male': 'en-IN-ArjunNeural', 'female': 'en-IN-AartiNeural'},\n",
        "    \"en-GB\": {'male': 'en-GB-ThomasNeural', 'female': 'en-GB-MiaNeural'},\n",
        "    \"en-US\":{\"male\": \"en-US-JasonNeural\", \"female\": \"en-US-JessaNeural\"}\n",
        "    # Add more languages and voices as needed\n",
        "\n",
        "}\n",
        "\n",
        "    voices = voices1[langCode]\n",
        "\n",
        "    output_dir = \"output_directory\"\n",
        "    final_output_file = \"final_output.wav\"\n",
        "    print(data)\n",
        "    final_audio_path = await generate_dialogue_audio(data, voices, output_dir, final_output_file,s_degree)\n",
        "    print(f\"Final audio saved at {final_audio_path}\")\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15ywyaJrXtAw",
        "outputId": "5f6fa184-9eeb-42a3-8dc7-87fa8e970130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is python\n",
            "enter langcode:en-US\n",
            "enter time range in seconds:50\n",
            "enter the degree0.01\n",
            "[{'male': \"Welcome to our podcast, today we're going to talk about Python, cheerful\"}, {'female': \"I'm excited to learn about Python, it's a popular programming language, excited\"}, {'male': \"That's right, Python is a high-level language that's easy to learn and versatile, calm\"}, {'female': 'It was created in the late 1980s by Guido van Rossum, and has since become a favorite among developers, friendly'}, {'male': 'Python is widely used in web development, data analysis, and artificial intelligence, serious'}, {'female': \"It's also used in scientific computing, education, and research, gentle\"}, {'male': 'One of the key features of Python is its simplicity and readability, making it a great language for beginners, hopeful'}, {'female': 'Python has a large and active community, with many libraries and frameworks available, enthusiastic'}, {'male': 'Some of the most popular applications of Python include machine learning, data visualization, and automation, excited'}, {'female': \"So, if you're interested in learning more about Python, be sure to tune in to our next episode, cheerful\"}]\n",
            "Final audio saved at final_output.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SyO13ZNdYASD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
